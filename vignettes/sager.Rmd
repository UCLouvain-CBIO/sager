---
title: "Using the `sager` package to import and analyse `sage` results in R"
author:
  - name: Laurent Gatto
    affiliation:
    - Computational Biology and Bioinformatics, UCLouvain
    email: laurent.gatto@uclouvain.be
output:
  BiocStyle::html_document:
    self_contained: yes
    toc: true
    toc_float: true
    toc_depth: 2
    code_folding: show
date: "`r doc_date()`"
package: "`r pkg_ver('sager')`"
vignette: >
  %\VignetteIndexEntry{The sager package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    crop = NULL ## Related to https://stat.ethz.ch/pipermail/bioc-devel/2020-April/016656.html
    )
suppressPackageStartupMessages(library("BiocStyle"))
```


# Introduction

## The `sager` package

[Sage](https://lazear.github.io/sage/) is a new cross-platform,
extremely performant, open source proteomics search engine [Michael
Lazear](https://github.com/lazear). It uses mzML files as input, is
parameterised by a [json
file](https://github.com/lazear/sage/blob/master/DOCS.md) and is
executed from the command line. In addition to peptide identification,
sage also includes a variety of advanced features such as retention
time prediction and quantification (both isobaric & LFQ). It produces
two files: `results.sage.tsv` with the identification results and,
when configured to quantify features, `quant.tsv`.

The `sager` package uses these two files as input. It facilitates
their import into established Bioconductor classes:

- Identification results are parsed and imported as
  [PSMatch::PSM()](https://rformassspectrometry.github.io/PSMatch/)
  objects with `sagePSM()`.

- Quantitation (and identification) results are parsed, merged and
  imported as
  [QFeatures::QFeatures()](https://rformassspectrometry.github.io/QFeatures/articles/QFeatures.html)
  objects with `sageQFeatures()`.

- Sage results can also be integrated with a
  [Spectra::Spectra()](https://rformassspectrometry.github.io/Spectra/)
  instance (holding the raw data) into a
  [MsExperiment::MsExperiment()](https://rformassspectrometry.github.io/MsExperiment/)
  object, as documented in this document.

The goal of the `sager` package can thus be summarised as a way to
leverage the existing [R for Mass
Spectrometry](https://www.rformassspectrometry.org/) and
[Bioconductor](https://bioconductor.org/) infrastructure to analyse
sage results.

## Installation instructions

To install `sager` and its dependencies, you'll need the `BiocManager`
package, that can be installed from CRAN (unless you already have it):

```{r installbiocmanager, eval = FALSE}
if (!requireNamespace("BiocManager"))
    install.packages("BiocManager")
```

Note that `sager` is under constant development, and thus will depend
on some under-development dependencies, that haven't made it into the
stable releases yet. Here are the instructions to install these:

To install the *devel* version of `PSMatch`:

```{r installpsmatch, eval = FALSE}
BiocManager::install("RforMassSpectrometry/PSMatch")
```

To install `sager` and its dependencies, you can run the following
command:

```{r installsager, eval = FALSE}
BiocManager::install("UCLouvain-CBIO/sager")
```


# Analysing `sage` results

## Example data

```{r loadpkg}
library(sager)
```

The `sager` package provides example identification and quantitation
(procuced by `sage`) and the raw data (`mzML` files) that were used
the generate the former.

```{r dataavailability}
sagerAvailableData()
```

Data can be added with the `sagerAddData()` function, that avoid
downloading data files if they are already available in the package's
local cache directory:

```{r dataadd}
sagerAddData()
```

For details, including updating local data and their provenance,
please see the `?sagerData` manual page.

## Identification data

As noted above, identification data is handled by the
[PSMatch](https://rformassspectrometry.github.io/PSMatch/)
package. This section only provides a very short example of how to use
it. For more details, see the package's [website and
vignettes](https://rformassspectrometry.github.io/PSMatch/).

```{r sagePSM, message = FALSE}
library(PSMatch)
psm <- sagePSM(sagerIdData())
psm
```

Here we briefly visualise the hyperscore and spectrum FDR densities
for the forward and decoy/reverse hits:

```{r ggplot, message = FALSE}
library(ggplot2)
data.frame(psm) |>
    ggplot(aes(x = hyperscore,
               colour = label)) +
    geom_density()
```

```{r ggplog2}
data.frame(psm) |>
    ggplot(aes(x = spectrum_fdr,
               colour = label)) +
    geom_density()
```

Below, we filter the PSMs removing decoy hits, PSMs of rank > 1 (none
in the small testing data), shared peptides (none in the small testing
data) and those that have a spectrum FDR below 0.05:


```{r filterPSM}
psm <- filterPSMs(psm) |>
    filterPsmFdr()
```

This leaves us with `r nrow(psm)` PSMs matched against
`r length(unique(psm$scannr))` scans.

```{r}
psm
```

## Quantitative data

As noted above, quantitation data is handled by the
[QFeatures](https://rformassspectrometry.github.io/QFeatures/)
package. This section only provides a very short example of how to use
it. For more details, see the package's [website and
vignettes](https://rformassspectrometry.github.io/QFeatures/).

We will also make use of some function from the
[scp](https://github.com/UCLouvain-CBIO/scp) package.

```{r, message = FALSE}
library(QFeatures)
library(scp)
```

The quantitation data has been produced from running `sage` on three
raw data files. These three files can correspond to two different
experimental designs:

1. The three acquisitions correspond to three fractions of the same
   set of 11 multiplexed samples. In this case, that we'll call the
   *Multiple fractions for the same set of samples*, we end up with a
   single quantitation matrix with 11 columns and row containing the
   features from all files.

2. The three acquisitions correspond to single acquisitions from 3
   different sets of 11 samples. In this case, that we'll call the
   *Different sets of samples per acquisition*, we end up with three
   quantitation matrices, each with 11 columns and rows containing the
   features from the respective files.

Both sitations are illustrated below using the `sageQFeatures()`
function , and a differenciated by the value of the `splitBy`
argument.

### Multiple fractions for the same set of samples

Let's read the data in, specifying that the tables should not be split
into different quantitative assays.

```{r qf1}
qf1 <- sageQFeatures(sagerQuantData(), sagerIdData(), splitBy = NULL)
qf1
```

The piped commands below implement the following worflow:

1. Filter decoy features (i.e. those with a label of -1).
2. Only keep features of rank 1.
3. Keep features that have a spectrum FDR smaller than 0.05.
4. Replace 0s by `NA`, to make missing values explicit.
5. Log-transform quantitative values.
6. Normalise data using median centring.
7. Aggregate features into protein-level quantities by computing the
   median and ignoring missing values.


```{r qf1process}
qf1 |>
    filterFeatures(~ label > 0) |>            ## 1
    filterFeatures(~ rank == 1) |>            ## 2
    filterFeatures(~ spectrum_fdr < 0.05) |>  ## 3
    zeroIsNA(1) |>                            ## 4
    logTransform(i = 1, name = "log_sage") |> ## 5
    normalize(i = "log_sage",                 ## 6
              name = "norm_sage",
              method = "center.median") |>
    aggregateFeatures(i = "norm_sage",        ## 7
                      name = "proteins",
                      fcol = "proteins",
                      fun = colMedians,
                      na.rm = TRUE) -> qf1
```

The new `QFeatures` object contains `r length(qf1)` assays:

```{r}
qf1
```

The pipeline can then be visualised as shown below:

```{r}
plot(qf1)
```

### Different sets of samples per acquisition

```{r qf2}
qf <- sageQFeatures(sagerQuantData(), sagerIdData())
qf
```

Annotate data:

```{r}
renameqf <- function(x) sub("\\.mzML", "", sub("^.+hrMS2_", "", x))
qf$filename <- rep(names(qf), each = 11)
qf$tmt_tag <- rep(paste0("tmt_", 1:11), length(qf))
qf$acquisition <- renameqf(qf$filename)
names(qf) <- paste0("psm", renameqf(names(qf)))
qf <- renamePrimary(qf, paste(qf$acquisition, qf$tmt_tag, sep = "."))
colnames(qf) <- CharacterList(lapply(colnames(qf), renameqf))
```

```{r}
qf
colData(qf)
```

Data processing:

```{r}
qf |>
    filterFeatures(~ label > 0) |>           ## 1
    filterFeatures(~ rank == 1) |>           ## 2
    filterFeatures(~ spectrum_fdr < 0.05) |> ## 3
    zeroIsNA(1:3) |>                         ## 4
    logTransform(i = 1:3,                    ## 5
                 name = paste0("log_", names(qf))) |>
    aggregateFeaturesOverAssays(i = 4:6,     ## 6
                                fcol = "peptide",
                                name = sub("psm", "peptide", names(qf)),
                                fun = colMedians,
                                na.rm = TRUE) |>
    joinAssays(i = 7:9,                      ## 7
               name = "peptides") |>
    normalize(i = 10,                        ## 8
              name = "norm_peptides",
              method = "center.mean") |>
    aggregateFeatures(i = "norm_peptides",   ## 9
                      name = "proteins",
                      fcol = "proteins",
                      fun = colMedians,
                      na.rm = TRUE) -> qf
```


```{r}
qf
```

The pipeline can then be visualised as shown below:

```{r}
plot(qf)
```

## Raw data

We have seen above how to import and process identification and
quantitation data produced by sage using standard R/Bioconductor
tools. Our main goal is to integrate these with the raw MS data that
was used to generate them.

Let's start by importing these raw data into R as a `Spectra`
object. The three mzML files can be retrieved with the
`sagerMzMLData()` function.

```{r spectra, message = FALSE}
library(Spectra)
sp <- Spectra(sagerMzMLData())
sp
```

# Combining raw, quantitation and identification data

## Defining keys

We can now create dedicates *keys* to identify features in the
different data produced above. Let's start with the spectra within the
`sp` object. Later, we will create a similar key in the `QFeatures`
and `PSM` objects generated above.

The goal of these keys will be to identify matching features across
data types, such as for example to match de MS spectra to the PSMs and
peptides or proteins. These different data types can be stored
together in an `MsExperiment` object, and matched through one or
multiple keys.

We can add a key (by default, names `.KEY` that will identify a
feature/scan by concatenating the scan number and the file in which
that scan was acquired.

```{r addkeySpectra}
sp$filename <- basename(dataOrigin(sp))
sp <- addKEY(sp, vars = c("filename", "spectrumId"))
head(sp$.KEY)
```

Let's do the same of the PSM object created above:

```{r addkeyPSM}
psm <- addKEY(psm, vars = c("filename", "scannr"))
head(psm$.KEY)
```

And finally, with the QFeatures object.

```{r addkeyQFeatures}
qf <- addKEY(qf, vars = c("file", "scannr"))
```

Running `addKEY` on a `QFeatures` object will only add a key to assays
that do have the relevant variables:

```{r}
sapply(rowData(qf), function(x) ".KEY" %in% names(x))
head(unname(rowData(qf[["psmA5"]])$.KEY))
```

Let's now bundle these three types of data together into and
`MsExperiment` object:

```{r mse}
library(MsExperiment)
mse <- MsExperiment()
spectra(mse) <- sp
qdata(mse) <- qf
otherData(mse)$PSM <- psm
```

```{r}
mse
```

## Searching for features across data types

Each data element `mse` is referenced by the same key. We can now
query for such keys direcly on the `MsExperiment` object, that will
percolate the request to its components.

```{r}
k <- c("subset_dq_00084_11cell_90min_hrMS2_A5.mzML.controllerType=0 controllerNumber=1 scan=31852",
       "subset_dq_00087_11cell_90min_hrMS2_A11.mzML.controllerType=0 controllerNumber=1 scan=32666")

subsetByKEY(mse, k)
```

It is however not convenient to search an arbitrary key. The more
useful usecase would be to look for a protein of interest, for
example, and then identify the features across other data types using
the relevant key(s).

Let's imagine that protein *DNLI3_HUMAN* is of interest to us. It is
referenced as `"sp|P49916|DNLI3_HUMAN"` in our data. The
`dropEmptyAssay()` simply drops assays that didn't reference the
protein of interest - it is used to simplify the output here.


```{r}
qdata(mse)["sp|P49916|DNLI3_HUMAN", , ] |>
    dropEmptyAssays()
```

These are features that we might be interested in tracking across all
data using their key... which we can easily retrieve with the
`getKEY()` function:

```{r, message=FALSE}
qdata(mse)["sp|P49916|DNLI3_HUMAN", , ] |>
    dropEmptyAssays() |>
    getKEY()
```

Given that `getKEY()` is run on a `QFeatures` object, it returns the
keys of all assays. Let's extract the unique keys as a character:

```{r, message=FALSE}
my_key <- qdata(mse)["sp|P49916|DNLI3_HUMAN", , ] |>
    dropEmptyAssays() |>
    getKEY() |>
    unlist() |>
    unique()
my_key
```

And now use `mykey` to subset the different component of the
`MsExperiment` object:

```{r}
my_mse <- subsetByKEY(mse, my_key)
my_mse
```

From the above, we can see that *DNLI3_HUMAN* was identified and
quantified by a single peptides, that has the following quantitation
profile acorss the 11 samples...

```{r}
assay(qdata(my_mse)[[3]])
```

... and that that peptides was matched by a single spectrum, shown
below:

```{r}
plotSpectra(spectra(my_mse))
```

# Misc

## Getting help

Please [open an issue](https://github.com/UCLouvain-CBIO/sager/issues)
on the package's Github repository.

<!-- ## Citing `sager` -->

<!-- ```{r citation} -->
<!-- citation("sager") -->
<!-- ``` -->

## Session information

```{r si, echo = FALSE}
sessionInfo()
```
